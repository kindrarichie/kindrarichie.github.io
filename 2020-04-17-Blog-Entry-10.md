---
layout: default
---

## Blog Post 10

This week I completed module 8 from the AWS training and worked on [documentation](https://github.com/alexcoward/Project2/wiki/Database-Backup-Strategy) for the group project. 

---

### AWS Module 8: Databases

By accurately recording, updating, and tracking data on an efficient and regular basis, companies can use the immense potential from the insights that they obtain from their data. Database management systems are the crucial link for managing this data.

A new generation of applications has emerged, which created a new set of requirements for databases. These applications need databases to store terabytes to petabytes of new types of data, provide access to the data with millisecond latency, process millions of requests per second, and scale to support millions of users anywhere in the world. To support these requirements, you need both relational and non-relational databases built to handle the specific needs of your applications. AWS offers a broad range of databases that are built for your specific application use cases.


<br>


#### Topics

-**Amazon Relational Database Service** 
<br>
AWS solutions typically fall into one of two categories: unmanaged or managed.

Unmanaged services are typically provisioned in discrete portions as specified by the user. You must manage how the service responds to changes in load, errors, and situations where resources become unavailable. The benefit to using an unmanaged service is that you have more fine-tuned control over how your solution handles changes in load, errors, and situations where resources become unavailable.

Managed services require the user to configure them. Managed services typically require less configuration. Features such as scaling, fault-tolerance, and availability would be handled automatically and internally by Amazon.

When you run your own relational database, you are responsible for several administrative tasks, such as server maintenance and energy footprint, software, installation and patching, and database backups. These tasks take resources from other items on your to-do list, and require expertise in several areas.

Amazon RDS is a managed service that sets up and operates a relational database in the cloud.
Amazon RDS provides cost-efficient and resizable capacity, while automating time-consuming administrative tasks.

What does the term managed services mean?
When your database is on premises, the database administrator is responsible for everything. Tasks include optimizing applications and queries; setting up the hardware; patching the hardware; setting up networking and power; and managing heating, ventilation, and air conditioning (HVAC).
If you move to a database that runs on an Amazon Elastic Compute Cloud (Amazon EC2) instance, you no longer need to manage the underlying hardware or handle data center operations. However, you are still responsible for patching the OS and handling all software and backup operations.
If you set up your database on Amazon RDS or Amazon Aurora, you reduce your administrative responsibilities. 
With Amazon RDS, you manage your application optimization. 

The basic building block of Amazon RDS is the database instance. A database instance is an isolated database environment that can contain multiple user-created databases. The resources in a database instance are determined by its database instance class, and the type of storage is dictated by the type of disks.

When you choose to create a database instance, you must first specify which database engine to run. Amazon RDS currently supports six databases: MySQL, Amazon Aurora, Microsoft SQL Server, PostgreSQL, MariaDB, and Oracle.

The basic functionality of Amazon RDS is the same whether or not it runs in a VPC. Subnets in a VPC are associated with a single Availability Zone, so when you select the subnet, you are also choosing the Availability Zone (or physical location) for your database instance.

One of the most powerful features of Amazon RDS is the ability to configure your database instance for high availability with a Multi-AZ deployment. Running a database instance in a Multi-AZ deployment can enhance availability during planned system maintenance, and it can help protect your databases against database instance failure and Availability Zone disruption.

Amazon RDS also supports the creation of read replicas for MySQL, MariaDB, PostgreSQL, and Amazon Aurora. Updates that are made to the source database instance are asynchronously copied to the read replica instance. You can reduce the load on your source database instance by routing read queries from your applications to the read replica. Read replicas can be created in a different Region than the master database which can help satisfy disaster recovery requirements or reduce latency by directing reads to a read replica that is closer to the user.

Amazon RDS works well for web/mobile applications, ecommerce applications, and mobile/online games that need a database with high throughput, massive storage scalability, and high availability. 

For circumstances when you should not use Amazon RDS, consider either using a NoSQL database solution (such as DynamoDB) or running your relational database engine on Amazon EC2 instances instead of Amazon RDS (which will provide you with more options for customizing your database).

When you begin to estimate the cost of Amazon RDS, you must consider the clock hours of service time, which are resources that incur charges when they are running.

Consider the database purchase type; On-Demand Instances vs Reserved. 

Consider provisioned storage. There is no additional charge for backup storage of up to 100 percent of your provisioned database storage for an active database instance. After the database instance is terminated, backup storage is billed per GB, per month.

Also consider the number of input and output requests that are made to the database.

Consider the deployment type; Single Availability Zone vs. multiple Availability Zones. 

Finally, consider data transfer. Inbound data transfer is free, and outbound data transfer costs are tiered.

Amazon RDS supports demanding database applications. You can choose between two solid state drive (SSD)-backed storage options: one option is optimized for high-performance Online Transactional Processing (OLTP) applications, and the other option works well for cost-effective, general-purpose use.
<br>
<br>
-**Amazon DynamoDB** 
<br>
Review of the differences between these two types of databases:
<br>
• A relational database (RDB) works with structured data that is organized by tables, records, and columns. RDBs establish a well-defined relationship between database tables. RDBs use structured query language (SQL), which is a standard user application that provides a programming interface for database interaction. Relational databases might have difficulties scaling out horizontally or working with semistructured data, and might also require many joins for normalized data.
<br>
• A non-relational database is any database that does not follow the relational model that is provided by traditional relational database management systems (RDBMS). Non-relational databases have grown in popularity because they were designed to overcome the limitations of relational databases for handling the demands of variable structured data. Non-relational databases scale out horizontally, and they can work with unstructured and semistructured data.


DynamoDB is a fast and flexible NoSQL database service for all applications that need consistent, single-digit-millisecond latency at any scale.

Amazon manages all the underlying data infrastructure for this service and redundantly stores data across multiple facilities in a native US Region as part of the fault-tolerant architecture. With DynamoDB, you can create tables and items. You can add items to a table. The system automatically partitions your data and has table storage to meet workload requirements. There is no practical limit on the number of items that you can store in a table.

One of the benefits of a NoSQL database is that items in the same table can have different attributes. 

All the data in DynamoDB is stored on solid state drives (SSDs) and its simple query language enables consistent low-latency query performance. In addition to scaling storage, DynamoDB also enables you to provision the amount of read or write throughput that you need for your table. DynamoDB tables can be scaled to handle the increased numbers of read/write requests with manual provisioning. Alternatively, you can enable automatic scaling so that DynamoDB monitors the load on the table and automatically increases or decreases the provisioned throughput.

Key features include global tables that enable you to automatically replicate across your choice of AWS Regions, encryption at rest, and item Time-to-Live (TTL)

The core DynamoDB components are tables, items, and attributes. 
<br>
A table is a collection of data. Items are a group of attributes that is uniquely identifiable among all the other items. Attributes are a fundamental data element, something that does not need to be broken down any further.

DynamoDB supports two different kinds of primary keys. The partition key is a simple primary key, which is composed of one attribute called the sort key. The partition key and sort key are also known as the composite primary key, which is composed of two attributes.

As data grows, table data is partitioned and indexed by the primary key.
You can retrieve data from a DynamoDB table in two different ways: 
<br>
<br>
• In the first method, the query operation takes advantage of partitioning to effectively locate items by using the primary key.
<br>
• The second method is via a scan, which enables you to locate items in the table by matching conditions on non-key attributes. The second method gives you the flexibility to locate items by other attributes. However, the operation is less efficient.

To take full advantage of query operations and DynamoDB, it's important to think about the key that you use to uniquely identify items in the DynamoDB table. You can set up a simple primary key that is based on a single attribute of the data values with a uniform distribution, such as the Globally Unique Identifier (GUID) or other random identifiers.

Key Takeaways:
<br>
<br>
DynamoDB runs exclusively on SSDs, and it supports document and key-value store models.
DynamoDB works well for mobile, web, gaming, ad tech, and Internet of Things (IoT) applications. It’s accessible via the console, the AWS CLI, and API calls.

The ability to scale your tables in terms of both storage and provision throughput makes DynamoDB a good fit for structured data from the web, mobile, and IoT applications. DynamoDB is also used in latency-sensitive applications. The predictable query performance—even in large tables—makes it useful for cases where variable latency could cause significant impact to the user experience or to business goals, such as adtech or gaming.
The DynamoDB Global Tables feature reduces the work of replicating data between Regions and resolving update conflicts. It replicates your DynamoDB tables automatically across your choice of AWS Regions. Global Tables can help applications stay available and performant for business continuity.
<br>
<br>

-**Amazon Redshift** 
<br>
Amazon Redshift is a fast, fully managed data warehouse that makes it simple and cost-effective to analyze all your data by using standard SQL and your existing business intelligence (BI) tools.

Amazon Redshift is a fast and powerful, fully managed data warehouse that is simple and cost-effective to set up, use, and scale. It enables you to run complex analytic queries against petabytes of structured data by using sophisticated query optimization, columnar storage on high-performance local disks, and massively parallel query execution. 

Like other AWS services, you only pay for what you use. You can get started for as little as 25 cents per hour and, at scale, Amazon Redshift can deliver storage and processing for approximately $1,000 dollars per terabyte per year (with 3-Year Partial Upfront Reserved Instance pricing).
The Amazon Redshift Spectrum feature enables you to run queries against exabytes of data directly in Amazon S3.

You can automate most of the common administrative tasks to manage, monitor, and scale your Amazon Redshift cluster. Your cluster can be scaled up and down as your needs change. With Amazon Redshift, security is built in, and it is designed to provide strong encryption of your data both at rest and in transit.

Amazon Redshift supports standard SQL. It also provides high-performance Java Database Connectivity (JDBC) and Open Database Connectivity (ODBC) connectors, which enable you to use the SQL clients and BI tools of your choice.

Amazon Redshift can help you reduce hardware and software costs.

Key Takeaways:
<br>
<br>
Amazon Redshift is a fast, fully managed data warehouse service. You can scale with no downtime by adding more nodes. Amazon Redshift automatically adds the nodes to your cluster and redistributes the data for maximum performance. Amazon Redshift is designed to consistently deliver high performance. Amazon Redshift uses columnar storage and a massively parallel processing architecture. These features parallelize and distribute data and queries across multiple nodes. Amazon Redshift also automatically monitors your cluster and backs up your data. Encryption is built in—you only need to enable it.
<br>
<br>
-**Amazon Aurora** 
<br>
Amazon Aurora is a MySQL-and PostgreSQL-compatible relational database that is built for the cloud. It combines the performance and availability of high-end commercial databases with the simplicity and cost-effectiveness of open-source databases. As a fully managed service, Aurora can automate tasks like provisioning, patching, backup, recovery, failure detection, and repair.

Amazon Aurora is highly available and it offers a fast, distributed storage subsystem. You only pay for the services and features that you use. It integrates with features such as AWS Database Migration Service (AWS DMS) and the AWS Schema Conversion Tool. 

Compared with Amazon RDS, it has high availability and resilient design. It stores multiple copies of your data across multiple Availability Zones with continuous backups to Amazon S3. Amazon Aurora can use up to 15 read replicas to reduce the possibility of losing your data. Amazon Aurora is designed for instant crash recovery if your primary database becomes unhealthy.

Amazon Aurora does not need to replay the redo log from the last database checkpoint. It performs this on every read operation. This reduces the restart time after a database crash. The buffer cache is moved out of the database process, making it available immediately at restart. This reduces the need for you to throttle access until the cache is repopulated to avoid brownouts.

Key Takeaways:

Amazon Aurora is a highly available and cost-effective managed relational database. Aurora offers a distributed, high-performance storage subsystem. It can reduce database costs while improving the reliability of the database. It has fault-tolerant and self-healing storage built for the cloud. Aurora replicates multiple copies of your data across multiple Availability Zones, and it continuously backs up your data to Amazon S3. Multiple levels of security are available, including network isolation by using Amazon VPC; encryption at rest by using keys that you create and control through AWS Key Management Service (AWS KMS); and encryption of data in transit by using Secure Sockets Layer (SSL). The Amazon Aurora database engine is compatible with existing MySQL and PostgreSQL open source databases. Amazon Aurora is fully managed by Amazon RDS. Aurora automates database management tasks, such as hardware provisioning, software patching, setup, configuration, or backups.
<br>
<br>





[back](../blog.html)
