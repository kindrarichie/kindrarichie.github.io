---
layout: default
---

## Blog Post 8

Coursework has continued online due to COVID-19. 

I continued the AWS training. 

---

### AWS Module 6: Compute

#### Topics

-**Compute Services Overview** 
Summary of what each compute service offers:
<br>
<br>
• Amazon Elastic Compute Cloud (Amazon EC2) provides resizable virtual machines. 
<br>
• Amazon EC2 Auto Scaling supports application availability by allowing you to define conditions that will automatically launch or terminate EC2 instances.
<br>
• Amazon Elastic Container Registry (Amazon ECR) is used to store and retrieve Docker images.
<br>
• Amazon Elastic Container Service (Amazon ECS) is a container orchestration service that supports Docker.
<br>
• VMware Cloud on AWS enables you to provision a hybrid cloud without custom hardware.
<br>
• AWS Elastic Beanstalk provides a simple way to run and manage web applications. 
<br>
• AWS Lambda is a serverless compute solution. You pay only for the compute time that you use.
<br>
• Amazon Elastic Kubernetes Service (Amazon EKS) enables you to run managed Kubernetes on AWS.
<br>
• Amazon Lightsail provides a simple-to-use service for building an application or website. • AWS Batch provides a tool for running batch jobs at any scale. 
<br>
• AWS Fargate provides a way to run containers that reduce the need for you to manage servers or clusters.
<br>
• AWS Outposts provides a way to run select AWS services in your on-premises data center. 
<br>
• AWS Serverless Application Repository provides a way to discover, deploy, and publish serverless applications.

Each AWS compute service belongs to one of four broad categories: virtual machines (VMs) that provide infrastructure as a service (IaaS), serverless, container-based, and platform as a service (PaaS).

Amazon EC2 provides virtual machines, and you can think of it as infrastructure as a service (IaaS). IaaS services provide flexibility and leave many of the server management responsibilities to you. 

AWS Lambda is a zero-administration compute platform. AWS Lambda enables you to run code without provisioning or managing servers. You pay only for the compute time that is consumed. 

Container-based services—including Amazon Elastic Container Service, Amazon Elastic Kubernetes Service, AWS Fargate, and Amazon Elastic Container Registry—enable you to run multiple workloads on a single operating system (OS). Containers spin up more quickly than virtual machines, thus offering responsiveness.

AWS Elastic Beanstalk provides a platform as a service (PaaS). It facilitates the quick deployment of applications that you create by providing all the application services that you need. AWS manages the OS, the application server, and the other infrastructure components so that you can focus on developing your application code.

Best practices include: 

• Evaluate the available compute options
<br>
• Understand the available compute configuration options 
<br>
• Collect computer-related metrics 
<br>
• Use the available elasticity of resources 
<br>
• Re-evaluate compute needs based on metrics
<br>
<br>
-**Amazon EC2** 
Running servers on-premises is an expensive undertaking. Amazon Elastic Compute Cloud (Amazon EC2) provides virtual machines where you can host the same kinds of applications that you might run on a traditional on-premises server. Some common uses for EC2 instances include, but are not limited to: Application servers, Web servers, Database servers, Game servers, Mail servers, File servers, Computing servers, and Proxy servers.

The EC2 in Amazon EC2 stands for Elastic Compute Cloud: 

• Elastic refers to the fact that you can easily increase or decrease the number of servers
you run to support an application automatically, and you can also increase or decrease the size of existing servers.
<br>
• Compute refers to reason why most users run servers in the first place, which is to host running applications or process data—actions that require compute resources, including processing power (CPU) and memory (RAM).
<br>
• Cloud refers to the fact that the EC2 instances that you run are hosted in the cloud.

Instances launch from Amazon Machine Images (AMIs), which are effectively virtual machine templates. You can control traffic to and from instances by using security groups. The Launch Instance Wizard makes it easy to launch an instance. 


An AMI includes the following components: 

• A template for the root volume of the instance. A root volume typically contains an operating system (OS) and everything that was installed in that OS (applications, libraries, etc.). Amazon EC2 copies the template to the root volume of a new EC2 instance, and then starts it.
<br>
• Launch permissions that control which AWS accounts can use the AMI. 
<br>
• A block device mapping that specifies the volumes to attach to the instance (if any) when it is launched.

You can choose many AMIs: 

• Quick Start – AWS offers a number of pre-built AMIs for launching your instances.  
• My AMIs – These AMIs are AMIs that you created.
<br>
• AWS Marketplace – The AWS Marketplace offers a digital catalog that lists thousands of software solutions. 
<br>
• Community AMIs – These AMIs are created by people all around the world. These AMIs are not checked by AWS, so use them at your own risk. 

When you create an AMI, Amazon EC2 stops the instance, creates a snapshot of its root volume, and finally registers the snapshot as an AMI. After an AMI is registered, the AMI can be used to launch new instances in the same AWS Region. 


Amazon EC2 provides a selection of instance types that optimized to fit different use cases. Instance types comprise varying combinations of CPU, memory, storage, and networking capacity. Instance type categories include general purpose, compute optimized, memory optimized, storage optimized, and accelerated computing instances.

When you look at an EC2 instance type, you will see that its name has several parts. For example, consider the T type. T is the family name, which is then followed by a number.  The number is the generation number of that type. So, a t3 instance is the third generation of the T family. In general, instance types that are of a higher generation are more powerful and provide a better value for the price. The next part of the name is the size portion of the instance. When you compare sizes, it is important to look at the coefficient portion of the size category.
For example, a t3.2xlarge has twice the vCPU and memory of a t3.xlarge. It is also important to note that network bandwidth is also tied to the size of the Amazon EC2 instance. If you will run jobs that will be very network-intensive, you might be required to increase the instance specifications to meet your needs.

Instance types vary in several ways, including: CPU type, CPU or core count, storage type, storage amount, memory amount, and network performance. T3 instances are general purpose instances that provide a baseline level of CPU performance with the ability to burst above the baseline. Use cases for this type of instance include websites and web applications, development environments. C5 instances are optimized for compute-intensive workloads, and deliver cost-effective high performance at a low price per compute ratio. Use cases include scientific modeling, batch processing. R5 instances are optimized for memory-intensive applications. Use cases include high-performance databases, data mining and analysis.

It is also important to consider your network bandwidth requirements. Each instance type provides a documented network performance level. When you launch multiple new EC2 instances, Amazon EC2 attempts to place the instances so that they are spread out across the underlying hardware by default. It does this to minimize correlated failures. However, if you want to specify specific placement criteria, you can use placement groups to influence the placement of a group of interdependent instances to meet the needs of your workload. 

After you have choose an AMI and an instance type, you must specify the network location where the EC2 instance will be deployed. The choice of Region must be made before you start the Launch Instance Wizard. When you launch an instance in a default VPC, AWS will assign it a public IP address by default. When you launch an instance into a nondefault VPC, the subnet has an attribute that determines whether instances launched into that subnet receive a public IP address from the public IPv4 address pool. By default, AWS will not assign a public IP address to instances that are launched in a nondefault subnet. 

It is common to use EC2 instances to run an application that must make secure API calls to other AWS services. To support these use cases, AWS enables you to attach an AWS Identity and Access Management (IAM) role to an EC2 instance. You should never store AWS credentials on an EC2 instance. An instance profile is a container for an IAM role. You can attach an IAM role when you launch the instance and also attach a role to an already running EC2 instance. 

When you create your EC2 instances, you have the option of passing user data to the instance. User data can automate the completion of installations and configurations at instance launch.

When you launch an EC2 instance, you can configure storage options. For each volume that your instance will have, you can specify the size of the disks, the volume types, and whether the storage will be retained if the instance is terminated. You can also specify if encryption should be used.

Amazon Elastic Block Store (Amazon EBS) is an easy-to-use, high-performance durable block storage service that is designed to be used with Amazon EC2 for both throughput-and transaction-intensive workloads. Only instances that are backed by Amazon EBS can be stopped. 

Amazon EC2 Instance Store provides temporary block-level storage for your instance. This storage is located on disks that are physically attached to the host computer. Instance Store works well when you must temporarily store information that changes frequently, such as buffers, caches, scratch data, and other temporary content. You can also use Instance Store for data that is replicated across a fleet of instances, such as a load balanced pool of web servers.

Amazon Elastic File System (Amazon EFS) provides a simple, scalable, fully managed elastic Network File System (NFS) file system for use with AWS Cloud services and on-premises resources. 

Amazon Simple Storage Service (Amazon S3) is an object storage service that offers scalability, data availability, security, and performance. 

A tag is a label that you assign to an AWS resource. Each tag consists of a key and an optional value, both of which you define. Tags enable you to categorize AWS resources, such as EC2 instances, in different ways. Tag keys and tag values are case-sensitive.

A security group acts as a virtual firewall that controls network traffic for one or more instances. You can add rules to each security group. Rules allow traffic to or from its associated instances. When AWS decides whether to allow traffic to reach an instance, all the rules from all the security groups that are associated with the instance are evaluated. When you define a rule, you can specify the allowable source of the network communication (inbound rules) or destination (outbound rules). The source can be an IP address, an IP address range, another security group, a gateway VPC endpoint, or anywhere (which means that all sources will be allowed). Network access control lists (network ACLs) can also be used are firewalls to protect subnets in a VPC.

Amazon EC2 uses public–key cryptography to encrypt and decrypt login information. The technology uses a public key to encrypt a piece of data, and then the recipient uses the private key to decrypt the data. The public and private keys are known as a key pair. 

An instance can be in one of the following states: Pending, Running, Rebooting, Shutting down, Terminated, Stopping, Stopped.

A public IP address is an IPv4 address that is reachable from the internet. Each instance that receives a public IP address is also given an external DNS hostname. If you require a persistent public IP address, you might want to associate an Elastic IP address with the instance. To associate an Elastic IP address, you must first allocate a new Elastic IP address in the Region where the instance exists. By default, all AWS accounts are limited to five (5) Elastic IP addresses per Region because public (IPv4) internet addresses are a scarce public resource. However, this is a soft limit.

Instance metadata is data about your instance. You can view it while you are connected to the instance. To access it in a browser, go to the following URL: http://169.254.169.254/latest/meta-data/. The data can also be read programmatically, such as from a terminal window that has the cURL utility. In the terminal window, run curl http://169.254.169.254/latest/meta-data/. Any user data that is specified at instance launch can also be accessed at the following URL: http://169.254.169.254/latest/user-data. 

You can monitor your instances by using Amazon CloudWatch, which collects and processes raw data from Amazon EC2 into readable, near-real-time metrics. These statistics are recorded for a period of 15 months, so you can access historical information and gain a better perspective on how your web application or service is performing. By default, Amazon EC2 provides basic monitoring, which sends metric data to CloudWatch in 5-minute periods. To send metric data for your instance to CloudWatch in 1-minute periods, you can enable detailed monitoring on the instance. 
<br>
<br>
-**Amazon EC2 versus a managed service like Amazon Relational Database Service**
With Amazon RDS for SQL Server, you can meet a number of requirements and improve security, database performance, scalability, and ease of management.

Improve Manageability for SQL Server with Pre-configured Parameters, Upgrade Monitoring and Metrics, Receive DB Event Notifications, Enable Automatic Software Patching, Scale in a Few Clicks, Improve Backup and Disaster Recovery.
<br>
<br>
-**Amazon EC2 Cost Optimization**

Amazon offers different pricing models to choose from when you want to run EC2 instances:

Per second billing is only available for On-Demand Instances, Reserved Instances, and Spot Instances that run Amazon Linux or Ubuntu.
On-Demand Instances are eligible for the AWS Free Tier. They have the lowest upfront cost and the most flexibility. 
Dedicated Instances are instances that run in a virtual private cloud (VPC) on hardware that’s dedicated to a single customer. 
Reserved Instance enable you to reserve computing capacity for 1-year or 3-year term with lower hourly running costs. 
Scheduled Reserved Instances enable you to purchase capacity reservations that recur on a daily, weekly, or monthly basis, with a specified duration, for a 1-year term. You pay for the time that the instances are scheduled, even if you do not use them.
Spot Instances enable you to bid on unused EC2 instances, which can lower your costs. The hourly price for a Spot Instance fluctuates depending on supply and demand. Your Spot Instance runs whenever your bid exceeds the current market price.


Each Amazon EC2 pricing model provides a different set of benefits: 

On-Demand Instances offer the most flexibility, with no long-term contract and low rates. Works well for spiky workloads or if you only need to test or run an application for a short time (for example, during application development or testing). Sometimes, your workloads are unpredictable, and On-Demand Instances are a good choice for these cases.
Spot Instances provide large scale at a significantly discounted price. Spot Instances are a good choice if your applications can tolerate interruption with a 2-minute warning notification. By default, instances are terminated, but you can configure them to stop or hibernate instead. Common use cases include fault-tolerant applications such as web servers, API backends, and big data processing. 
Reserved Instances are a good choice if you have predictable or steady-state compute needs (for example, an instance that you know you want to keep running most or all of the time for months or years).
Dedicated Hosts are a good choice when you have licensing restrictions for the software you want to run on Amazon EC2, or when you have specific compliance or regulatory requirements that preclude you from using the other deployment options.

To optimize costs, you must consider four consistent, powerful drivers:

• Right-size – Choose the right balance of instance types. Notice when servers can be either sized down or turned off, and still meet your performance requirements. AWS offers approximately 60 instance types and sizes. Right-sizing is the process of reviewing deployed resources and looking for opportunities to downsize when possible. To right size: Select the cheapest instance available that still meets your performance requirements. - Review CPU, RAM, storage, and network utilization to identify instances that could be downsized. For right-sizing, use techniques such as load testing to your advantage. - Use Amazon CloudWatch metrics and set up custom metrics.
<br>
• Increase elasticity – Design your deployments to reduce the amount of server capacity that is idle by implementing deployments that are elastic, such as deployments that use automatic scaling to handle peak loads. One form of elasticity is to create, start, or use EC2 instances when they are needed, but then to turn them off when they are not in use. Elasticity is one of the central tenets of the cloud, but customers often go through a learning process to operationalize elasticity to drive cost savings. As a rule of thumb, you should target 20–30 percent of your Amazon EC2 instances to run as On-Demand Instances or Spot Instances. 
<br>
• Optimal pricing model – Recognize the available pricing options. Analyze your usage patterns so that you can run EC2 instances with the right mix of pricing options. Consider the application architecture. Does the functionality provided by your application need to run on an EC2 virtual machine? Perhaps by making use of the AWS Lambda service instead.
<br>
• Optimize storage choices – Analyze the storage requirements of your deployments. Reduce unused storage overhead when possible, and choose less expensive storage options if they can still meet your requirements for storage performance. One way you can accomplish this is by resizing EBS volumes. There are also a variety of EBS volume types. Choose the least expensive type that still meets your performance requirements. Delete these unneeded EBS snapshots. Try to identify the most appropriate destination for specific types of data.

Tagging helps provide information about what resources are being used by whom and for what purpose. You can activate cost allocation tags in the Billing and Cost Management console, and AWS can generate a cost allocation report with usage and costs grouped by your active tags. Use AWS services such as AWS Trusted Advisor. Cost-optimization efforts are typically more successful when the responsibility for cost optimization is assigned to an individual or to a team.
<br>
<br>
-**Container Services**
Containers are a method of operating system virtualization that enables you to run an application and its dependencies in resource-isolated processes. By using containers, you can easily package an application's code, configurations, and dependencies into easy-to-use building blocks that deliver environmental consistency, operational efficiency, developer productivity, and version control. Containers are smaller than virtual machines, and do not contain an entire operating system. Instead, containers share a virtualized operating system and run as resource-isolated processes, which ensure quick, reliable, and consistent deployments. Containers deliver environmental consistency because the application’s code, configurations, and dependencies are packaged into a single object. In terms of space, container images are usually an order of magnitude smaller than virtual machines.

Docker is a software platform that packages software (such as applications) into containers. By using Docker, you can quickly deploy and scale applications into any environment. Docker is best used as a solution when you want to: Standardize environments, Reduce conflicts between language stacks and versions, Use containers as a service, Run microservices using standardized code deployments, and Require portability for data processing. 

One significant difference between containers and vm's is that virtual machines run directly on a hypervisor, but containers can run on any Linux OS if they have the appropriate kernel feature support and the Docker daemon is present. This makes containers very portable. 

You could launch one or more Amazon EC2 instances, install Docker on each instance, and manage and run the Docker containers on those Amazon EC2 instances yourself. While that is an option, AWS provides a service called Amazon Elastic Container Service (Amazon ECS) that simplifies container management. Amazon Elastic Container Service (Amazon ECS) is a highly scalable, high-performance container management service that supports Docker containers. Amazon ECS enables you to easily run applications on a managed cluster of Amazon EC2 instances. Essential Amazon ECS features include the ability to: Launch up to tens of thousands of Docker containers in seconds, Monitor container deployment, Manage the state of the cluster that runs the containers, Schedule containers by using a built-in scheduler or a third-party scheduler (for example, Apache Mesos or Blox). Amazon ECS clusters can also use Spot Instances and Reserved Instances. To prepare your application to run on Amazon ECS, you create a task definition which is a text file that describes one or more containers, up to a maximum of ten, that form your application. It can be thought of as a blueprint for your application. A task is the instantiation of a task definition within a cluster. You can specify the number of tasks that will run on your cluster. The Amazon ECS task scheduler is responsible for placing tasks within your cluster. When Amazon ECS runs the containers that make up your task, it places them on an ECS cluster. The cluster (when you choose the EC2 launch type) consists of a group of EC2 instances each of which is running an Amazon ECS container agent.

When you create an Amazon ECS cluster, you have three options: A Networking Only cluster (powered by AWS Fargate), An EC2 Linux + Networking cluster, An EC2 Windows + Networking cluster. If you choose one of the two EC2 launch type options, you will then be prompted to choose whether the cluster EC2 instances will run as On-Demand Instances or Spot Instances. In addition, you will need to specify many details about the EC2 instances that will make up your cluster. Amazon ECS keeps track of all the CPU, memory, and other resources in your cluster. 
If you choose the networking-only Fargate launch type, then the cluster that will run your containers will be managed by AWS. The Fargate option enables you to focus on designing and building your applications.

Kubernetes is open source software for container orchestration. Kubernetes can work with many containerization technologies, including Docker. Kubernetes enables you to deploy and manage containerized applications at scale. With Kubernetes, you can run any type of containerized application by using the same toolset in both on-premises data centers and the cloud. Kubernetes manages a cluster of compute instances (called nodes). It runs containers on the cluster, which are based on where compute resources are available and the resource requirements of each container. Containers are run in logical groupings called pods. A key advantage of Kubernetes is that you can use it to run your containerized applications anywhere without needing to change your operational tooling. 

You could launch one or more Amazon EC2 instances, install Docker on each instance, install Kubernetes on the cluster, and manage and run Kubernetes yourself. While that is an option, AWS provides a service called Amazon Elastic Kubernetes Service (Amazon EKS) that simplifies the management of Kubernetes clusters. Amazon Elastic Kubernetes Service (Amazon EKS) is a managed Kubernetes service that makes it easy for you to run Kubernetes on AWS without needing to install, operate, and maintain your own Kubernetes control plane. Amazon offers both Amazon ECS and Amazon EKS (they are both capable of orchestrating Docker containers) to provide customers with flexible options. 


Amazon Elastic Container Registry (Amazon ECR) is a fully managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images. It is integrated with Amazon ECS, so you can store, run, and manage container images for applications that run on Amazon ECS. Specify the Amazon ECR repository in your task definition, and Amazon ECS will retrieve the appropriate images for your applications. You can transfer your container images to and from Amazon ECS via HTTPS. Your images are also automatically encrypted at rest using Amazon S3 server-side encryption.

Some key takeaways from this section include: Containers can hold everything that an application needs to run. Docker is a software platform that packages software into containers. A single application can span multiple containers. Amazon Elastic Container Service (Amazon ECS) orchestrates the execution of Docker containers. Kubernetes is open source software for container orchestration. Amazon Elastic Kubernetes Service (Amazon EKS) enables you to run Kubernetes on AWS. Amazon Elastic Container Registry (Amazon ECR) enables you to store, manage, and deploy your Docker containers.
<br>
<br>
-**Introduction to AWS Lambda** 
AWS Lambda is an event-driven, serverless compute service. Lambda enables you to run code without provisioning or managing servers. You create a Lambda function, which is the AWS resource that contains the code that you upload. You then set the Lambda function to be triggered, either on a scheduled basis or in response to an event. Your code only runs when it is triggered. You pay only for the compute time you consume—you are not charged when your code is not running.

With Lambda, there are no new languages, tools, or frameworks to learn. Lambda supports multiple programming languages. Lambda completely automates the administration. It manages all the infrastructure to run your code on highly available, fault-tolerant infrastructure, which enables you to focus on building differentiated backend services. Lambda provides built-in fault tolerance. It maintains compute capacity across multiple Availability Zones in each Region. You can orchestrate multiple Lambda functions for complex or long-running tasks by building workflows with AWS Step Functions. With Step Functions and Lambda, you can build stateful, long-running processes for applications and backends. With Lambda, you pay only for the requests that are served and the compute time that is required to run your code. 

An event source is an AWS service or a developer-created application that produces events that trigger an AWS Lambda function to run. Some services publish events to Lambda by invoking the Lambda function directly. These services that invoke Lambda functions asynchronously include, but are not limited to, Amazon S3 and Amazon CloudWatch Events. Lambda can also poll resources in other services that do not publish events to Lambda. You can invoke Lambda functions directly with the Lambda console, the Lambda API, the AWS software development kit (SDK), the AWS CLI, and AWS toolkits. The direct invocation approach can be useful, such as when you are developing a mobile app. 

AWS Lambda automatically monitors Lambda functions by using Amazon CloudWatch.

A Lambda function is the custom code that you write to process events and Lambda executes the Lambda function on your behalf. When you use the AWS Management Console to create a Lambda function, you give the function a name. Then, you specify: The runtime environment the function will use. An execution role (to grant IAM permission to the function so that it can interact with other AWS services as necessary). A trigger. Add your function code (use the provided code editor or upload a file that contains your code). Specify the memory in MB to allocate to your function (128 MB to 3,008 MB). Optionally specify environment variables, description, timeout, the specific virtual private cloud (VPC) to run the function in, tags you would like to use, and other settings. All of the above settings end up in a Lambda deployment package which is a ZIP archive that contains your function code and dependencies. 

AWS Lambda limits the amount of compute and storage resources that you can use to run and store functions. There are limits on the deployment package size of a function (250 MB). A layer is a ZIP archive that contains libraries, a custom runtime, or other dependencies. With layers, you can use libraries in your function without needing to include them in your deployment package. Using layers can help avoid reaching the size limit for deployment package. Layers are also a good way to share code and data between Lambda functions. Limits are either soft or hard. Soft limits on an account can potentially be relaxed by submitting a support ticket and providing justification for the request. Hard limits cannot be increased.

Some key takeaways from this section of the module include:
<br>
• Serverless computing enables you to build and run applications and services without provisioning or managing servers.
<br>
• AWS Lambda is a serverless compute service that provides built-in fault tolerance and automatic scaling.
<br>
• An event source is an AWS service or developer-created application that triggers a Lambda function to run.
<br>
• The maximum memory allocation for a single Lambda function is 3,008 MB. 
<br>
• The maximum execution time for a Lambda function is 15 minutes.
<br>
<br>
-**Introduction to AWS Elastic Beanstalk** 
AWS Elastic Beanstalk is a platform as a service (or PaaS) that facilitates the quick deployment, scaling, and management of your web applications and services. Upload your code and Elastic Beanstalk automatically handles the deployment, from capacity provisioning and load balancing to automatic scaling and monitoring application health. At the same time, you retain full control over the AWS resources that power your application, and you can access the underlying resources at any time. There is no additional charge for AWS Elastic Beanstalk. You pay for the AWS resources you create to store and run your application. You only pay for what you use, as you use it. There are no minimum fees and no upfront commitments.

AWS Elastic Beanstalk enables you to deploy your code through the AWS Management Console, the AWS Command Line Interface (AWS CLI), Visual Studio, and Eclipse. AWS Elastic Beanstalk deploys your code on Apache Tomcat for Java applications; Apache HTTP Server for PHP and Python applications; NGINX or Apache HTTP Server for Node.js applications; Passenger or Puma for Ruby applications; and Microsoft Internet Information Services (IIS) for .NET applications, Java SE, Docker, and Go.

You can improve your developer productivity by focusing on writing code instead of managing and configuring servers, databases, load balancers, firewalls, and networks. Elastic Beanstalk is difficult to outgrow. With Elastic Beanstalk, your application can handle peaks in workload or traffic while minimizing your costs. You have the freedom to select the AWS resources—such as Amazon EC2 instance type—that are optimal for your application. 
<br>
<br>





[back](../blog.html)
